name: Deploy AKS Zabbix Infrastructure (Terraform & ARM)

on:
  # Only run on manual trigger or when infrastructure files change
  push:
    branches: [ main, develop ]
    paths:
      - 'infra/**'
      - 'k8s/**'
      - '.github/workflows/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'infra/**'
      - 'k8s/**'
      - '.github/workflows/**'
  workflow_dispatch:
    inputs:
      deployment_type:
        description: 'Type of deployment'
        required: true
        default: 'application-only'
        type: choice
        options:
        - full
        - infrastructure-only
        - application-only
        - redeploy-clean
      infrastructure_method:
        description: 'Infrastructure deployment method'
        required: true
        default: 'terraform'
        type: choice
        options:
        - terraform
        - arm
        - both
      terraform_mode:
        description: 'Terraform execution mode'
        required: false
        default: 'plan-and-apply'
        type: choice
        options:
        - plan-only
        - plan-and-apply
        - apply-existing-plan
      force_powershell:
        description: 'Force PowerShell deployment (skip Azure CLI)'
        required: false
        default: false
        type: boolean
      reset_database:
        description: 'Reset Zabbix database (WARNING: destroys data)'
        required: false
        default: false
        type: boolean
      environment_suffix:
        description: 'Environment suffix (optional)'
        required: false
        default: ''
        type: string
      debug_mode:
        description: 'Enable debug logging'
        required: false
        default: false
        type: boolean

env:
  AZURE_RESOURCE_GROUP: 'rg-devops-pops-eastus'
  AZURE_LOCATION: 'eastus'
  AZURE_SUBSCRIPTION_ID: 'd9b2a1cf-f99b-4f9e-a6cf-c79a078406bf'
  AKS_CLUSTER_NAME: 'aks-devops-eastus'
  CONTAINER_REGISTRY_NAME: 'acrdevopseastus'
  DEPLOYMENT_TYPE: ${{ github.event.inputs.deployment_type || (github.event_name == 'push' && 'full') || 'application-only' }}
  INFRASTRUCTURE_METHOD: ${{ github.event.inputs.infrastructure_method || 'terraform' }}
  TERRAFORM_MODE: ${{ github.event.inputs.terraform_mode || 'plan-and-apply' }}
  FORCE_POWERSHELL: ${{ github.event.inputs.force_powershell || 'false' }}
  RESET_DATABASE: ${{ github.event.inputs.reset_database || 'false' }}
  DEBUG_MODE: ${{ github.event.inputs.debug_mode || 'false' }}
  ENV_SUFFIX: ${{ github.event.inputs.environment_suffix || '' }}

jobs:
  # Infrastructure Deployment
  deploy-infrastructure:
    runs-on: ubuntu-latest
    environment: production
    if: ${{ github.event.inputs.deployment_type == 'full' || github.event.inputs.deployment_type == 'infrastructure-only' || github.event.inputs.deployment_type == 'redeploy-clean' || github.event_name == 'push' || github.event_name == 'pull_request' }}
    outputs:
      aks-cluster-name: ${{ steps.deploy-infra.outputs.AKS_CLUSTER_NAME }}
      resource-group: ${{ steps.deploy-infra.outputs.AZURE_RESOURCE_GROUP }}
      container-registry: ${{ steps.deploy-infra.outputs.CONTAINER_REGISTRY_ENDPOINT }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Display Deployment Configuration
      run: |
        echo "=== Deployment Configuration ==="
        echo "Deployment Type: ${{ github.event.inputs.deployment_type || 'application-only' }}"
        echo "Infrastructure Method: ${{ github.event.inputs.infrastructure_method || 'terraform' }}"
        echo "Terraform Mode: ${{ github.event.inputs.terraform_mode || 'plan-and-apply' }}"
        echo "Force PowerShell: ${{ github.event.inputs.force_powershell || 'false' }}"
        echo "Reset Database: ${{ github.event.inputs.reset_database || 'false' }}"
        echo "Debug Mode: ${{ github.event.inputs.debug_mode || 'false' }}"
        echo "Environment Suffix: ${{ github.event.inputs.environment_suffix || 'none' }}"
        echo "Resource Group: ${{ env.AZURE_RESOURCE_GROUP }}"
        echo "Location: ${{ env.AZURE_LOCATION }}"
        echo "Run Number: ${{ github.run_number }}"
        echo "Actor: ${{ github.actor }}"
        echo "Triggered by: ${{ github.event_name }}"
        
        if [ "${{ github.event.inputs.debug_mode }}" = "true" ]; then
          echo "DEBUG_MODE=true" >> $GITHUB_ENV
          echo "üêõ Debug mode enabled - detailed logging will be provided"
        fi

    - name: Azure CLI Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}

    - name: Set up Azure CLI
      run: |
        az account set --subscription ${{ env.AZURE_SUBSCRIPTION_ID }}
        az account show

    - name: Install Terraform
      run: |
        echo "üîß Installing Terraform..."
        
        # Download and install Terraform
        TERRAFORM_VERSION="1.6.0"
        curl -Lo terraform.zip "https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/terraform_${TERRAFORM_VERSION}_linux_amd64.zip"
        unzip terraform.zip
        sudo mv terraform /usr/local/bin/
        rm terraform.zip
        
        # Verify installation
        terraform version
        echo "‚úÖ Terraform installed successfully"

    - name: Validate Infrastructure Method Selection
      run: |
        echo "üîç Validating infrastructure deployment method..."
        echo "Selected method: ${{ env.INFRASTRUCTURE_METHOD }}"
        echo "Terraform mode: ${{ env.TERRAFORM_MODE }}"
        
        case "${{ env.INFRASTRUCTURE_METHOD }}" in
          "terraform")
            echo "‚úÖ Will use Terraform for infrastructure deployment"
            echo "DEPLOY_TERRAFORM=true" >> $GITHUB_ENV
            echo "DEPLOY_ARM=false" >> $GITHUB_ENV
            ;;
          "arm")
            echo "‚úÖ Will use ARM templates for infrastructure deployment"
            echo "DEPLOY_TERRAFORM=false" >> $GITHUB_ENV
            echo "DEPLOY_ARM=true" >> $GITHUB_ENV
            ;;
          "both")
            echo "‚úÖ Will try Terraform first, then ARM as fallback"
            echo "DEPLOY_TERRAFORM=true" >> $GITHUB_ENV
            echo "DEPLOY_ARM=true" >> $GITHUB_ENV
            ;;
          *)
            echo "‚ùå Invalid infrastructure method: ${{ env.INFRASTRUCTURE_METHOD }}"
            exit 1
            ;;
        esac
        
        # Set Terraform execution mode
        case "${{ env.TERRAFORM_MODE }}" in
          "plan-only")
            echo "üìã Will only create Terraform plan for review"
            echo "TF_PLAN_ONLY=true" >> $GITHUB_ENV
            echo "TF_APPLY_EXISTING=false" >> $GITHUB_ENV
            ;;
          "apply-existing-plan")
            echo "üöÄ Will apply existing Terraform plan"
            echo "TF_PLAN_ONLY=false" >> $GITHUB_ENV
            echo "TF_APPLY_EXISTING=true" >> $GITHUB_ENV
            ;;
          "plan-and-apply")
            echo "üìãüöÄ Will create plan and apply immediately"
            echo "TF_PLAN_ONLY=false" >> $GITHUB_ENV
            echo "TF_APPLY_EXISTING=false" >> $GITHUB_ENV
            ;;
          *)
            echo "‚ùå Invalid terraform mode: ${{ env.TERRAFORM_MODE }}"
            exit 1
            ;;
        esac

    - name: Prepare Terraform Environment
      if: ${{ env.INFRASTRUCTURE_METHOD == 'terraform' || env.INFRASTRUCTURE_METHOD == 'both' }}
      run: |
        echo "üîß Preparing Terraform environment..."
        
        # Navigate to Terraform directory
        cd infra/terraform
        
        # Generate consistent environment name (without run number to avoid resource conflicts)
        ENV_SUFFIX="${{ github.event.inputs.environment_suffix }}"
        if [ -n "$ENV_SUFFIX" ]; then
          ENV_NAME="zabbix-devops-${{ env.AZURE_LOCATION }}-$ENV_SUFFIX"
        else
          ENV_NAME="zabbix-devops-${{ env.AZURE_LOCATION }}"
        fi
        echo "Environment name: $ENV_NAME"
        echo "This will create resources with naming pattern: resourcename-devops-${{ env.AZURE_LOCATION }}"
        
        # Create terraform.tfvars file
        cat > terraform.tfvars << EOF
        resource_group_name = "${{ env.AZURE_RESOURCE_GROUP }}"
        location           = "${{ env.AZURE_LOCATION }}"
        environment_name   = "$ENV_NAME"
        
        # AKS Configuration
        kubernetes_version = "1.32"
        
        # Node Pool Configuration
        aks_system_node_count = 2
        aks_user_node_count   = 3
        aks_user_node_min_count = 2
        aks_user_node_max_count = 10
        
        # VM Sizes
        aks_system_vm_size = "Standard_D2s_v3"
        aks_user_vm_size   = "Standard_D4s_v3"
        
        # Feature Flags
        enable_auto_scaling  = true
        enable_azure_policy  = true
        enable_log_analytics = true
        
        # Monitoring
        log_analytics_retention_days = 30
        EOF
        
        echo "‚úÖ Terraform environment prepared"
        
        # Store environment name for later steps
        echo "TERRAFORM_ENV_NAME=$ENV_NAME" >> $GITHUB_ENV

    - name: Deploy Infrastructure with Terraform
      id: deploy-infra-terraform
      if: ${{ env.INFRASTRUCTURE_METHOD == 'terraform' || env.INFRASTRUCTURE_METHOD == 'both' }}
      continue-on-error: true
      run: |
        echo "üöÄ Starting Terraform deployment process..."
        echo "Mode: ${{ env.TERRAFORM_MODE }}"
        
        cd infra/terraform
        
        # Initialize Terraform
        echo "üì¶ Initializing Terraform..."
        terraform init
        
        # Temporarily disable Kubernetes provider during import to prevent configuration errors
        echo "üîß Temporarily disabling Kubernetes provider during import phase..."
        if [ -f "kubernetes-providers.tf" ]; then
          mv kubernetes-providers.tf kubernetes-providers.tf.disabled
          echo "   ‚úÖ Kubernetes provider temporarily disabled"
        else
          echo "   ‚ö†Ô∏è  kubernetes-providers.tf not found - continuing anyway"
        fi
        
        # Import existing resources if they exist (ignore errors for non-existent resources)
        echo "üì¶ Attempting to import existing resources..."
        set +e  # Don't exit on import errors
        
        # List all resources in the resource group first
        echo "üîç Listing all resources in resource group ${{ env.AZURE_RESOURCE_GROUP }}..."
        az resource list --resource-group "${{ env.AZURE_RESOURCE_GROUP }}" --output table || echo "‚ö†Ô∏è Failed to list resources"
        
        # Check current Terraform state
        echo "üîç Current Terraform state:"
        terraform state list || echo "No resources in state yet"
        
        # Check which specific resources exist in Azure
        echo "üîç Checking for specific resources that are causing conflicts..."
        
        # Function to check resource existence and get actual names
        # Simple resource listing
        echo "üîç Listing resources in resource group ${{ env.AZURE_RESOURCE_GROUP }}..."
        az resource list --resource-group "${{ env.AZURE_RESOURCE_GROUP }}" --output table || echo "‚ö†Ô∏è Failed to list resources"
        
        # Skip complex resource discovery - we know the exact resource names
        echo ">> Using known resource names for import..."
        
        # Import resources - simplified approach with better error handling
        echo ">> Importing resources using a simplified, robust approach..."
        
        # Function to safely import a resource with improved error handling and full diagnostics
        safe_import() {
            local tf_resource="$1"
            local azure_id="$2"
            local display_name="$3"
            
            echo ""
            echo "==> Processing $display_name..."
            echo "    Terraform resource: $tf_resource"
            echo "    Azure resource ID: $azure_id"
            
            # Check if resource is already in Terraform state
            if terraform state show "$tf_resource" >/dev/null 2>&1; then
                echo "    [INFO] Resource already in Terraform state - verifying..."
                # Get the actual ID from Terraform state (different approach)
                local current_id=""
                current_id=$(terraform state show "$tf_resource" 2>/dev/null | grep -E '^\s*id\s*=' | head -1 | sed -E 's/.*=\s*"([^"]+)".*/\1/' || echo "")
                
                if [ -n "$current_id" ] && [ "$current_id" = "$azure_id" ]; then
                    echo "    [SUCCESS] $display_name already correctly imported"
                    return 0
                else
                    echo "    [WARNING] State exists but may point to different resource or be corrupted"
                    echo "              Current ID in state: $current_id"
                    echo "              Expected ID: $azure_id"
                    echo "              Removing and re-importing..."
                    terraform state rm "$tf_resource" >/dev/null 2>&1 || echo "              Note: Failed to remove from state (might not exist)"
                fi
            fi
            
            # Verify the Azure resource exists
            echo "    [CHECK] Verifying resource exists in Azure..."
            if ! az resource show --ids "$azure_id" >/dev/null 2>&1; then
                echo "    [ERROR] Resource not found in Azure - skipping import"
                return 1
            fi
            echo "    [SUCCESS] Resource verified in Azure"
            
            # Attempt the import with detailed output capture
            echo "    [IMPORT] Importing $display_name into Terraform state..."
            local import_output=""
            local import_exit_code=0
            
            # Capture full output and exit code
            import_output=$(terraform import "$tf_resource" "$azure_id" 2>&1) || import_exit_code=$?
            
            # Analyze the output to determine success/failure
            local import_success=false
            if [ $import_exit_code -eq 0 ]; then
                # Check for success indicators in output
                if echo "$import_output" | grep -q "Import successful\|successfully imported\|Import prepared"; then
                    import_success=true
                fi
                # Also check if there are no error indicators
                if ! echo "$import_output" | grep -qi "error\|failed\|invalid"; then
                    import_success=true
                fi
            fi
            
            if [ "$import_success" = true ]; then
                echo "    [SUCCESS] Successfully imported $display_name"
                # Show success details if in debug mode
                if [ "${{ github.event.inputs.debug_mode }}" = "true" ]; then
                    echo "              Import output:"
                    echo "$import_output" | sed 's/^/              /' | tail -5
                fi
                return 0
            else
                echo "    [FAILED] Import failed for $display_name (exit code: $import_exit_code)"
                echo "             Full error output:"
                # Show complete error output, not just first 10 lines
                echo "$import_output" | sed 's/^/              /'
                echo ""
                echo "             Common causes and solutions:"
                echo "             - Resource definition in Terraform doesn't match actual Azure resource"
                echo "               Solution: Check Terraform resource configuration"
                echo "             - Missing dependencies in Terraform state" 
                echo "               Solution: Import dependencies first or run terraform refresh"
                echo "             - Resource provider registration issues"
                echo "               Solution: Register required providers in Azure"
                echo "             - Permissions issues"
                echo "               Solution: Verify service principal has required permissions"
                echo ""
                return 1
            fi
        }
        
        
        # Import critical resources in dependency order
        echo ""
        echo ">> Starting systematic resource import in dependency order..."
        
        # 1. Import Managed Identity (fundamental dependency for AKS)
        safe_import "azurerm_user_assigned_identity.aks" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/id-devops-eastus" \
            "Managed Identity"
        
        # 2. Import Log Analytics workspace (independent resource)
        safe_import "azurerm_log_analytics_workspace.main[0]" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.OperationalInsights/workspaces/law-devops-eastus" \
            "Log Analytics Workspace"
        
        # 3. Import Container Registry (independent resource)
        safe_import "azurerm_container_registry.main" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.ContainerRegistry/registries/acrdevopseastus" \
            "Container Registry"
        
        # 4. Import Virtual Network (required for subnets)
        safe_import "azurerm_virtual_network.main" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Network/virtualNetworks/vnet-devops-eastus" \
            "Virtual Network"
        
        # 5. Import Network Security Groups (independent, but required for associations)
        safe_import "azurerm_network_security_group.aks" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Network/networkSecurityGroups/nsg-aks-devops-eastus" \
            "AKS Network Security Group"
        
        safe_import "azurerm_network_security_group.appgw" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Network/networkSecurityGroups/nsg-appgw-devops-eastus" \
            "App Gateway Network Security Group"
        
        # 6. Import Public IP (independent, but required for App Gateway)
        safe_import "azurerm_public_ip.appgw" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Network/publicIPAddresses/pip-appgw-devops-eastus" \
            "Application Gateway Public IP"
        
        # 7. Import Subnets (depend on VNet)
        safe_import "azurerm_subnet.aks" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Network/virtualNetworks/vnet-devops-eastus/subnets/subnet-aks-devops-eastus" \
            "AKS Subnet"
        
        safe_import "azurerm_subnet.appgw" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Network/virtualNetworks/vnet-devops-eastus/subnets/subnet-appgw-devops-eastus" \
            "App Gateway Subnet"
        
        # 8. Import NSG associations (depend on both NSGs and Subnets)
        safe_import "azurerm_subnet_network_security_group_association.aks" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Network/virtualNetworks/vnet-devops-eastus/subnets/subnet-aks-devops-eastus" \
            "AKS NSG Association"
        
        safe_import "azurerm_subnet_network_security_group_association.appgw" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Network/virtualNetworks/vnet-devops-eastus/subnets/subnet-appgw-devops-eastus" \
            "App Gateway NSG Association"
        
        # 9. Import Application Gateway (depends on subnet and public IP)
        safe_import "azurerm_application_gateway.main" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Network/applicationGateways/appgw-devops-eastus" \
            "Application Gateway"
        
        # 10. Import AKS cluster (depends on managed identity, subnet, and optionally Log Analytics)
        safe_import "azurerm_kubernetes_cluster.main" \
            "/subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.ContainerService/managedClusters/aks-devops-eastus" \
            "AKS Cluster"
        
        # Re-enable Kubernetes provider after AKS import (if it was successfully imported)
        echo ""
        echo "üîß Re-enabling Kubernetes provider after AKS import..."
        if terraform state show "azurerm_kubernetes_cluster.main" >/dev/null 2>&1; then
          echo "   ‚úÖ AKS cluster found in state - enabling Kubernetes provider"
          if [ -f "kubernetes-providers.tf.disabled" ]; then
            mv kubernetes-providers.tf.disabled kubernetes-providers.tf
            echo "   ‚úÖ Kubernetes provider re-enabled"
            
            # Re-initialize Terraform with the Kubernetes provider
            echo "   üîÑ Re-initializing Terraform with Kubernetes provider..."
            terraform init
          else
            echo "   ‚ö†Ô∏è  kubernetes-providers.tf.disabled not found"
          fi
        else
          echo "   ‚ö†Ô∏è  AKS cluster not found in state - keeping Kubernetes provider disabled"
        fi
        
        
        set -e  # Re-enable exit on error
        echo ""
        echo ">> Import process completed"
        
        # Verify which resources were actually successfully imported
        echo ""
        echo ">> Verifying import results..."
        echo "================================"
        
        # Check each resource we tried to import - simplified version for GitHub Actions compatibility
        echo "Checking imported resources:"
        imported_count=0
        total_resources=13
        
        # Check each resource individually
        if terraform state show "azurerm_user_assigned_identity.aks" >/dev/null 2>&1; then
            echo "  [SUCCESS] Managed Identity - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] Managed Identity - not in Terraform state"
        fi
        
        if terraform state show "azurerm_log_analytics_workspace.main[0]" >/dev/null 2>&1; then
            echo "  [SUCCESS] Log Analytics Workspace - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] Log Analytics Workspace - not in Terraform state"
        fi
        
        if terraform state show "azurerm_container_registry.main" >/dev/null 2>&1; then
            echo "  [SUCCESS] Container Registry - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] Container Registry - not in Terraform state"
        fi
        
        if terraform state show "azurerm_virtual_network.main" >/dev/null 2>&1; then
            echo "  [SUCCESS] Virtual Network - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] Virtual Network - not in Terraform state"
        fi
        
        if terraform state show "azurerm_network_security_group.aks" >/dev/null 2>&1; then
            echo "  [SUCCESS] AKS Network Security Group - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] AKS Network Security Group - not in Terraform state"
        fi
        
        if terraform state show "azurerm_network_security_group.appgw" >/dev/null 2>&1; then
            echo "  [SUCCESS] App Gateway Network Security Group - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] App Gateway Network Security Group - not in Terraform state"
        fi
        
        if terraform state show "azurerm_public_ip.appgw" >/dev/null 2>&1; then
            echo "  [SUCCESS] Application Gateway Public IP - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] Application Gateway Public IP - not in Terraform state"
        fi
        
        if terraform state show "azurerm_subnet.aks" >/dev/null 2>&1; then
            echo "  [SUCCESS] AKS Subnet - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] AKS Subnet - not in Terraform state"
        fi
        
        if terraform state show "azurerm_subnet.appgw" >/dev/null 2>&1; then
            echo "  [SUCCESS] App Gateway Subnet - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] App Gateway Subnet - not in Terraform state"
        fi
        
        if terraform state show "azurerm_subnet_network_security_group_association.aks" >/dev/null 2>&1; then
            echo "  [SUCCESS] AKS NSG Association - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] AKS NSG Association - not in Terraform state"
        fi
        
        if terraform state show "azurerm_subnet_network_security_group_association.appgw" >/dev/null 2>&1; then
            echo "  [SUCCESS] App Gateway NSG Association - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] App Gateway NSG Association - not in Terraform state"
        fi
        
        if terraform state show "azurerm_application_gateway.main" >/dev/null 2>&1; then
            echo "  [SUCCESS] Application Gateway - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] Application Gateway - not in Terraform state"
        fi
        
        if terraform state show "azurerm_kubernetes_cluster.main" >/dev/null 2>&1; then
            echo "  [SUCCESS] AKS Cluster - in Terraform state"
            ((imported_count++))
        else
            echo "  [MISSING] AKS Cluster - not in Terraform state"
        fi
        
        echo ""
        echo "Import Summary: $imported_count/$total_resources resources successfully imported into Terraform state"
        echo ""
        
        # Show comprehensive state and comparison
        echo ""
        echo ">> Post-Import Analysis:"
        echo "========================"
        
        # Show final Terraform state
        echo "üîç Resources in Terraform state:"
        if terraform_state_list=$(terraform state list | sort); then
            if [ -n "$terraform_state_list" ]; then
                echo "$terraform_state_list" | sed 's/^/  /'
                terraform_count=$(echo "$terraform_state_list" | wc -l)
            else
                echo "  (No resources in Terraform state)"
                terraform_count=0
            fi
        else
            echo "  ‚ùå Failed to list Terraform state"
            terraform_count="unknown"
        fi
        
        # Show Azure resources in the resource group
        echo ""
        echo "üîç Resources in Azure resource group ${{ env.AZURE_RESOURCE_GROUP }}:"
        if azure_resources=$(az resource list --resource-group "${{ env.AZURE_RESOURCE_GROUP }}" --query '[].{Name:name, Type:type}' --output tsv 2>/dev/null | sort); then
            if [ -n "$azure_resources" ]; then
                echo "$azure_resources" | sed 's/^/  /'
                azure_count=$(echo "$azure_resources" | wc -l)
            else
                echo "  (No resources found in Azure resource group)"
                azure_count=0
            fi
        else
            echo "  ‚ùå Failed to list Azure resources"
            azure_count="unknown"
        fi
        
        echo ""
        echo "üìä Import Summary:"
        echo "  Resources in Terraform state: $terraform_count"
        echo "  Resources in Azure RG: $azure_count"
        
        # If counts differ significantly, provide guidance
        if [ "$terraform_count" != "unknown" ] && [ "$azure_count" != "unknown" ] && [ "$terraform_count" -lt $((azure_count - 5)) ]; then
            echo "  ‚ö†Ô∏è  Significant difference detected. This could indicate:"
            echo "     - Some Azure resources are not managed by this Terraform config"
            echo "     - Import failures due to configuration mismatches"
            echo "     - Resources created outside of Terraform"
            echo "     - This is normal if not all Azure resources are supposed to be in Terraform"
        fi
        
        # Final check: Ensure Kubernetes provider is enabled if AKS exists
        echo "üîç Final check: Kubernetes provider status..."
        if terraform state show "azurerm_kubernetes_cluster.main" >/dev/null 2>&1; then
          if [ ! -f "kubernetes-providers.tf" ]; then
            echo "   ‚ö†Ô∏è  AKS exists but Kubernetes provider is disabled - re-enabling..."
            if [ -f "kubernetes-providers.tf.disabled" ]; then
              mv kubernetes-providers.tf.disabled kubernetes-providers.tf
              terraform init
              echo "   ‚úÖ Kubernetes provider enabled"
            else
              echo "   ‚ùå kubernetes-providers.tf.disabled not found - this may cause issues"
            fi
          else
            echo "   ‚úÖ Kubernetes provider is properly enabled"
          fi
        else
          echo "   ‚ÑπÔ∏è  AKS not in state - Kubernetes provider will remain disabled"
        fi
        
        # Validate configuration
        echo "üîç Validating Terraform configuration..."
        if ! terraform validate; then
          echo "‚ùå Terraform validation failed"
          exit 1
        fi
        echo "‚úÖ Terraform configuration is valid"
        
        # Generate plan file name with timestamp
        PLAN_FILE="tfplan-${{ github.run_number }}-$(date +%s)"
        echo "PLAN_FILE=$PLAN_FILE" >> $GITHUB_ENV
        
        # Create plan
        echo "üìã Creating Terraform plan after import..."
        set +e  # Don't exit on plan errors
        terraform plan -out=$PLAN_FILE -detailed-exitcode 2>&1 | tee terraform-plan-output.txt
        PLAN_EXIT_CODE=${PIPESTATUS[0]}
        set -e  # Re-enable exit on error
        
        if [ $PLAN_EXIT_CODE -eq 1 ]; then
          echo ""
          echo "‚ùå Terraform plan failed due to errors"
          echo ">> Plan error details:"
          echo "====================="
          cat terraform-plan-output.txt | tail -50
          echo ""
          echo "üîç Common causes of plan failures after import:"
          echo "  - Terraform resource configuration doesn't match actual Azure resource"
          echo "  - Missing or incorrect resource dependencies"
          echo "  - Imported resource has properties not defined in Terraform"
          echo "  - Azure resource was modified outside of Terraform"
          echo ""
          echo "üí° Troubleshooting steps:"
          echo "  1. Check if resource definitions in Terraform match actual Azure resources"
          echo "  2. Verify all required properties are defined in Terraform configuration"
          echo "  3. Consider updating Terraform config to match current Azure resource state"
          echo "  4. Check for missing dependencies between resources"
          exit 1
        elif [ $PLAN_EXIT_CODE -eq 2 ]; then
          echo "üìã Terraform plan created with changes to apply"
          echo "PLAN_HAS_CHANGES=true" >> $GITHUB_ENV
          echo ">> Plan summary (first 30 lines):"
          terraform show -no-color $PLAN_FILE 2>/dev/null | head -30 || echo "Could not show plan details"
        else
          echo "üìã Terraform plan created with no changes"
          echo "PLAN_HAS_CHANGES=false" >> $GITHUB_ENV
        fi
        
        # Display plan summary
        echo "üìã Terraform Plan Summary:"
        terraform show -no-color $PLAN_FILE
        
        # Save plan as artifact for manual review
        echo "üíæ Saving plan for review..."
        terraform show -json $PLAN_FILE > terraform-plan.json
        terraform show -no-color $PLAN_FILE > terraform-plan.txt
        
        # Check execution mode
        if [ "${{ env.TERRAFORM_MODE }}" = "plan-only" ]; then
          echo "üìã Plan-only mode: Terraform plan created and saved"
          echo "üîç Review the plan and then run the workflow with 'apply-existing-plan' mode to apply"
          echo "DEPLOYMENT_SUCCESS=plan-created" >> $GITHUB_OUTPUT
          echo "PLAN_FILE=$PLAN_FILE" >> $GITHUB_OUTPUT
        elif [ "${{ env.TERRAFORM_MODE }}" = "apply-existing-plan" ]; then
          # Look for existing plan file
          EXISTING_PLAN=$(ls -t tfplan-* 2>/dev/null | head -n 1 || echo "")
          if [ -z "$EXISTING_PLAN" ]; then
            echo "‚ùå No existing plan found. Please run in 'plan-only' mode first."
            echo "DEPLOYMENT_SUCCESS=false" >> $GITHUB_OUTPUT
          else
            echo "üöÄ Applying existing plan: $EXISTING_PLAN"
            if terraform apply -auto-approve "$EXISTING_PLAN"; then
              echo "‚úÖ Terraform apply completed successfully"
              echo "DEPLOYMENT_SUCCESS=true" >> $GITHUB_OUTPUT
            else
              echo "‚ùå Terraform apply failed"
              echo "DEPLOYMENT_SUCCESS=false" >> $GITHUB_OUTPUT
            fi
          fi
        else
          # plan-and-apply mode
          echo "üöÄ Applying Terraform plan immediately..."
          if terraform apply -auto-approve $PLAN_FILE; then
            echo "‚úÖ Terraform deployment successful"
            echo "DEPLOYMENT_SUCCESS=true" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Terraform deployment failed"
            echo "DEPLOYMENT_SUCCESS=false" >> $GITHUB_OUTPUT
            exit 1
          fi
        fi
        
        # Capture outputs if deployment was successful
        if [ "${{ env.TERRAFORM_MODE }}" != "plan-only" ]; then
          echo "üìã Extracting Terraform outputs..."
          set +e  # Don't exit if output extraction fails
          AKS_CLUSTER_NAME=$(terraform output -raw AKS_CLUSTER_NAME 2>/dev/null || echo "")
          AZURE_RESOURCE_GROUP=$(terraform output -raw AZURE_RESOURCE_GROUP 2>/dev/null || echo "${{ env.AZURE_RESOURCE_GROUP }}")
          CONTAINER_REGISTRY_ENDPOINT=$(terraform output -raw CONTAINER_REGISTRY_ENDPOINT 2>/dev/null || echo "")
          set -e
          
          echo "AKS_CLUSTER_NAME=$AKS_CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "AZURE_RESOURCE_GROUP=$AZURE_RESOURCE_GROUP" >> $GITHUB_OUTPUT
          echo "CONTAINER_REGISTRY_ENDPOINT=$CONTAINER_REGISTRY_ENDPOINT" >> $GITHUB_OUTPUT
          echo "DEPLOYMENT_METHOD=terraform" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Infrastructure deployed successfully with Terraform!"
          echo "   AKS Cluster: $AKS_CLUSTER_NAME"
          echo "   Resource Group: $AZURE_RESOURCE_GROUP"
          echo "   Container Registry: $CONTAINER_REGISTRY_ENDPOINT"
          
          # Final cleanup: Ensure Kubernetes provider is properly enabled for future runs
          echo ""
          echo "üîß Final cleanup: Ensuring Kubernetes provider state is correct..."
          if [ -f "kubernetes-providers.tf.disabled" ]; then
            echo "   ‚ö†Ô∏è  Found disabled Kubernetes provider - moving to correct location"
            mv kubernetes-providers.tf.disabled kubernetes-providers.tf
            echo "   ‚úÖ Kubernetes provider file restored to correct location"
          else
            echo "   ‚úÖ Kubernetes provider state is already correct"
          fi
        fi

    - name: Cleanup Kubernetes Provider (Always Run)
      if: always() && (env.INFRASTRUCTURE_METHOD == 'terraform' || env.INFRASTRUCTURE_METHOD == 'both')
      run: |
        cd infra/terraform
        echo "üîß Cleanup: Ensuring Kubernetes provider is restored..."
        
        # Always try to restore the Kubernetes provider file if it was disabled
        if [ -f "kubernetes-providers.tf.disabled" ]; then
          echo "   üîÑ Restoring kubernetes-providers.tf from disabled state"
          mv kubernetes-providers.tf.disabled kubernetes-providers.tf
          echo "   ‚úÖ Kubernetes provider file restored"
        else
          echo "   ‚úÖ No cleanup needed - Kubernetes provider was not disabled or already restored"
        fi

    - name: Upload Terraform Plan Artifacts
      if: ${{ env.INFRASTRUCTURE_METHOD == 'terraform' || env.INFRASTRUCTURE_METHOD == 'both' }}
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan-${{ github.run_number }}
        path: |
          infra/terraform/terraform-plan.json
          infra/terraform/terraform-plan.txt
          infra/terraform/tfplan-*
        retention-days: 7

    - name: Pre-deployment Diagnostics
      if: ${{ steps.deploy-infra-terraform.outputs.DEPLOYMENT_SUCCESS != 'true' && env.INFRASTRUCTURE_METHOD == 'arm' }}
      run: |
        echo "üîç Running pre-deployment diagnostics for ARM template fallback..."
        
        # Check resource group access
        echo "Checking resource group access..."
        az group show --name ${{ env.AZURE_RESOURCE_GROUP }} --output table || {
          echo "‚ùå Cannot access resource group ${{ env.AZURE_RESOURCE_GROUP }}"
          exit 1
        }
        
        # Check resource providers
        echo "Checking required resource providers..."
        REQUIRED_PROVIDERS="Microsoft.ContainerService Microsoft.Network Microsoft.ContainerRegistry Microsoft.ManagedIdentity Microsoft.OperationalInsights"
        for provider in $REQUIRED_PROVIDERS; do
          STATUS=$(az provider show --namespace $provider --query registrationState -o tsv)
          echo "  $provider: $STATUS"
          if [ "$STATUS" != "Registered" ]; then
            echo "‚ö†Ô∏è Registering provider $provider..."
            az provider register --namespace $provider --wait
          fi
        done
        
        echo "‚úÖ Pre-deployment diagnostics completed"

    - name: Validate Terraform Configuration (if using Terraform)
      if: ${{ env.INFRASTRUCTURE_METHOD == 'terraform' || env.INFRASTRUCTURE_METHOD == 'both' }}
      run: |
        echo "üîç Validating Terraform configuration..."
        cd infra/terraform
        
        # Validate syntax
        if ! terraform validate; then
          echo "‚ùå Terraform validation failed"
          exit 1
        fi
        echo "‚úÖ Terraform configuration is valid"

    - name: Deploy Infrastructure with ARM Template (Fallback)
      id: deploy-infra-arm
      if: ${{ env.INFRASTRUCTURE_METHOD == 'arm' || (env.INFRASTRUCTURE_METHOD == 'both' && steps.deploy-infra-terraform.outputs.DEPLOYMENT_SUCCESS != 'true') }}
      run: |
        echo "üöÄ Deploying infrastructure using ARM template..."
        
        # Generate deployment name with timestamp
        TIMESTAMP=$(date +%s)
        ARM_DEPLOYMENT_NAME="zabbix-arm-deploy-${{ github.run_number }}-$TIMESTAMP"
        echo "ARM Deployment name: $ARM_DEPLOYMENT_NAME"
        
        # Generate environment name with DevOps naming convention (consistent with Terraform)
        ENV_SUFFIX="${{ github.event.inputs.environment_suffix }}"
        if [ -n "$ENV_SUFFIX" ]; then
          DEPLOYMENT_ENV_NAME="zabbix-devops-${{ env.AZURE_LOCATION }}-$ENV_SUFFIX"
        else
          DEPLOYMENT_ENV_NAME="zabbix-devops-${{ env.AZURE_LOCATION }}"
        fi
        
        echo "Deployment environment name: $DEPLOYMENT_ENV_NAME"
        echo "Resources will be named with pattern: resourcename-devops-${{ env.AZURE_LOCATION }}"
        
        # Deploy ARM template
        set +e  # Don't exit on error
        ARM_DEPLOYMENT_OUTPUT=$(timeout 1800 az deployment group create \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --template-file infra/main-arm.json \
          --parameters environmentName="$DEPLOYMENT_ENV_NAME" \
                       location="${{ env.AZURE_LOCATION }}" \
          --name "$ARM_DEPLOYMENT_NAME" \
          --mode Incremental \
          --output json \
          --only-show-errors 2>&1)
        ARM_DEPLOYMENT_EXIT_CODE=$?
        set -e  # Re-enable exit on error
        
        if [ $ARM_DEPLOYMENT_EXIT_CODE -ne 0 ]; then
          echo "‚ùå ARM template deployment failed with exit code $ARM_DEPLOYMENT_EXIT_CODE"
          echo "Error output:"
          echo "$ARM_DEPLOYMENT_OUTPUT"
          echo "DEPLOYMENT_SUCCESS=false" >> $GITHUB_OUTPUT
        else
          echo "‚úÖ ARM template deployment successful!"
          
          # Extract outputs
          AKS_CLUSTER_NAME=$(echo "$ARM_DEPLOYMENT_OUTPUT" | jq -r '.properties.outputs.AKS_CLUSTER_NAME.value // empty')
          CONTAINER_REGISTRY_ENDPOINT=$(echo "$ARM_DEPLOYMENT_OUTPUT" | jq -r '.properties.outputs.CONTAINER_REGISTRY_ENDPOINT.value // empty')
          
          if [ -z "$AKS_CLUSTER_NAME" ] || [ "$AKS_CLUSTER_NAME" = "null" ]; then
            echo "‚ùå Failed to get AKS cluster name from ARM deployment outputs"
            echo "DEPLOYMENT_SUCCESS=false" >> $GITHUB_OUTPUT
          else
            # Set outputs
            echo "AKS_CLUSTER_NAME=$AKS_CLUSTER_NAME" >> $GITHUB_OUTPUT
            echo "AZURE_RESOURCE_GROUP=${{ env.AZURE_RESOURCE_GROUP }}" >> $GITHUB_OUTPUT
            echo "CONTAINER_REGISTRY_ENDPOINT=$CONTAINER_REGISTRY_ENDPOINT" >> $GITHUB_OUTPUT
            echo "DEPLOYMENT_METHOD=arm" >> $GITHUB_OUTPUT
            echo "DEPLOYMENT_SUCCESS=true" >> $GITHUB_OUTPUT
            
            echo "‚úÖ ARM Infrastructure deployed successfully!"
            echo "   AKS Cluster: $AKS_CLUSTER_NAME"
            echo "   Resource Group: ${{ env.AZURE_RESOURCE_GROUP }}"
            echo "   Container Registry: $CONTAINER_REGISTRY_ENDPOINT"
          fi
        fi

    - name: Set Infrastructure Outputs
      id: deploy-infra
      run: |
        # Use outputs from whichever deployment method succeeded
        if [ "${{ steps.deploy-infra-terraform.outputs.DEPLOYMENT_SUCCESS }}" = "true" ]; then
          echo "Using Terraform deployment outputs"
          echo "AKS_CLUSTER_NAME=${{ steps.deploy-infra-terraform.outputs.AKS_CLUSTER_NAME }}" >> $GITHUB_OUTPUT
          echo "AZURE_RESOURCE_GROUP=${{ steps.deploy-infra-terraform.outputs.AZURE_RESOURCE_GROUP }}" >> $GITHUB_OUTPUT
          echo "CONTAINER_REGISTRY_ENDPOINT=${{ steps.deploy-infra-terraform.outputs.CONTAINER_REGISTRY_ENDPOINT }}" >> $GITHUB_OUTPUT
          echo "DEPLOYMENT_SUCCESS=true" >> $GITHUB_OUTPUT
          echo "‚úÖ Used Terraform for deployment" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ steps.deploy-infra-arm.outputs.DEPLOYMENT_SUCCESS }}" = "true" ]; then
          echo "Using ARM template deployment outputs"
          echo "AKS_CLUSTER_NAME=${{ steps.deploy-infra-arm.outputs.AKS_CLUSTER_NAME }}" >> $GITHUB_OUTPUT
          echo "AZURE_RESOURCE_GROUP=${{ steps.deploy-infra-arm.outputs.AZURE_RESOURCE_GROUP }}" >> $GITHUB_OUTPUT
          echo "CONTAINER_REGISTRY_ENDPOINT=${{ steps.deploy-infra-arm.outputs.CONTAINER_REGISTRY_ENDPOINT }}" >> $GITHUB_OUTPUT
          echo "DEPLOYMENT_SUCCESS=true" >> $GITHUB_OUTPUT
          echo "‚úÖ Used ARM template for deployment" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå All deployment methods failed or returned empty outputs" >> $GITHUB_STEP_SUMMARY
          echo "Terraform success: ${{ steps.deploy-infra-terraform.outputs.DEPLOYMENT_SUCCESS }}"
          echo "ARM success: ${{ steps.deploy-infra-arm.outputs.DEPLOYMENT_SUCCESS }}"
          echo "DEPLOYMENT_SUCCESS=false" >> $GITHUB_OUTPUT
          exit 1
        fi

    - name: Display Deployment Summary
      run: |
        echo ""
        echo "=== Final Deployment Results ==="
        if [ "${{ steps.deploy-infra-terraform.outputs.DEPLOYMENT_SUCCESS }}" = "true" ]; then
          echo "‚úÖ Deployment Method: Terraform"
          echo "AKS Cluster Name: ${{ steps.deploy-infra-terraform.outputs.AKS_CLUSTER_NAME }}"
          echo "Resource Group: ${{ steps.deploy-infra-terraform.outputs.AZURE_RESOURCE_GROUP }}"
          echo "Container Registry: ${{ steps.deploy-infra-terraform.outputs.CONTAINER_REGISTRY_ENDPOINT }}"
        elif [ "${{ steps.deploy-infra-arm.outputs.DEPLOYMENT_SUCCESS }}" = "true" ]; then
          echo "‚úÖ Deployment Method: ARM Template"
          echo "AKS Cluster Name: ${{ steps.deploy-infra-arm.outputs.AKS_CLUSTER_NAME }}"
          echo "Resource Group: ${{ steps.deploy-infra-arm.outputs.AZURE_RESOURCE_GROUP }}"
          echo "Container Registry: ${{ steps.deploy-infra-arm.outputs.CONTAINER_REGISTRY_ENDPOINT }}"
        else
          echo "‚ùå No successful deployment to display"
        fi

    - name: Get AKS credentials
      if: steps.deploy-infra.outputs.DEPLOYMENT_SUCCESS == 'true'
      run: |
        echo "üîë Getting AKS credentials..."
        echo "Cluster: ${{ env.AKS_CLUSTER_NAME }}"
        echo "Resource Group: ${{ env.AZURE_RESOURCE_GROUP }}"
        
        az aks get-credentials \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --name ${{ env.AKS_CLUSTER_NAME }} \
          --overwrite-existing

    - name: Verify AKS connection
      if: steps.deploy-infra.outputs.DEPLOYMENT_SUCCESS == 'true'
      run: |
        echo "üîç Verifying AKS cluster connection..."
        kubectl cluster-info
        kubectl get nodes
        kubectl get namespaces

  # Deploy Zabbix Application
  deploy-zabbix:
    needs: deploy-infrastructure
    runs-on: ubuntu-latest
    environment: production
    if: ${{ always() && (github.event.inputs.deployment_type == 'full' || github.event.inputs.deployment_type == 'application-only' || github.event.inputs.deployment_type == 'redeploy-clean' || github.event_name == 'push' || github.event_name == 'pull_request') && (needs.deploy-infrastructure.result == 'success' || github.event.inputs.deployment_type == 'application-only') }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Azure CLI Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}

    - name: Install and Setup kubectl
      run: |
        echo "üîß Setting up kubectl and Helm..."
        
        # Install kubectl if not available
        if ! command -v kubectl &> /dev/null; then
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
        fi
        
        # Install Helm if not available
        if ! command -v helm &> /dev/null; then
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
        fi
        
        echo "‚úÖ kubectl and Helm are ready"

    - name: Get AKS credentials
      run: |
        echo "üîë Getting AKS credentials for application deployment..."
        echo "Cluster: ${{ env.AKS_CLUSTER_NAME }}"
        echo "Resource Group: ${{ env.AZURE_RESOURCE_GROUP }}"
        
        az aks get-credentials \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --name ${{ env.AKS_CLUSTER_NAME }} \
          --overwrite-existing
        
        # Verify connection
        kubectl cluster-info
        kubectl get nodes
        echo "‚úÖ AKS connection verified"

    - name: Install Application Gateway Ingress Controller
      run: |
        echo "üöÄ Installing Application Gateway Ingress Controller (AGIC)..."
        
        # Calculate Application Gateway name
        APPGW_NAME="appgw-devops-eastus"
        echo "Using Application Gateway: $APPGW_NAME"
        
        # Add AGIC Helm repository
        helm repo add application-gateway-kubernetes-ingress https://appgwingress.blob.core.windows.net/ingress-azure-helm-package/
        helm repo update
        
        # Create namespace for AGIC
        kubectl create namespace agic --dry-run=client -o yaml | kubectl apply -f -
        
        # Install AGIC
        helm install agic application-gateway-kubernetes-ingress/ingress-azure \
          --namespace agic \
          --set appgw.name=$APPGW_NAME \
          --set appgw.resourceGroup=${{ env.AZURE_RESOURCE_GROUP }} \
          --set appgw.subscriptionId=${{ env.AZURE_SUBSCRIPTION_ID }} \
          --set appgw.usePrivateIP=false \
          --set kubernetes.watchNamespace=zabbix \
          --set armAuth.type=servicePrincipal \
          --set armAuth.secretJSON=$(echo '${{ secrets.AZURE_CREDENTIALS }}' | base64 -w0) \
          --wait || {
          echo "‚ö†Ô∏è AGIC installation failed, falling back to NGINX Ingress..."
          
          # Fallback to NGINX Ingress Controller
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
          helm repo update
          
          helm install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx \
            --create-namespace \
            --set controller.replicaCount=2 \
            --set controller.service.type=LoadBalancer \
            --set controller.service.annotations."service\.beta\.kubernetes\.io/azure-load-balancer-health-probe-request-path"=/healthz \
            --wait
        }
        
        echo "‚úÖ Ingress controller installation completed"

    - name: Deploy Zabbix Namespace and Configuration
      run: |
        kubectl apply -f k8s/zabbix-config.yaml
        kubectl get namespace zabbix

    - name: Cleanup Existing Zabbix Resources (Conditional)
      if: ${{ github.event.inputs.deployment_type == 'redeploy-clean' || github.event.inputs.reset_database == 'true' }}
      run: |
        echo "üßπ Cleaning up existing Zabbix resources for fresh deployment..."
        echo "Deployment Type: ${{ github.event.inputs.deployment_type }}"
        echo "Reset Database: ${{ github.event.inputs.reset_database }}"
        
        # Delete Zabbix deployments and services
        kubectl delete deployment --all -n zabbix --ignore-not-found=true
        kubectl delete service --all -n zabbix --ignore-not-found=true
        kubectl delete ingress --all -n zabbix --ignore-not-found=true
        kubectl delete configmap --all -n zabbix --ignore-not-found=true
        kubectl delete secret --all -n zabbix --ignore-not-found=true
        
        # Wait for pods to terminate
        kubectl wait --for=delete pods --all -n zabbix --timeout=120s || true
        
        # Clean up PVCs if database reset is requested
        if [ "${{ github.event.inputs.reset_database }}" = "true" ]; then
          echo "‚ö†Ô∏è RESETTING DATABASE - All data will be lost!"
          kubectl delete pvc -n zabbix --all --ignore-not-found=true
        fi
        
        echo "‚úÖ Cleanup completed"

    - name: Smart Cleanup for Regular Deployments
      if: ${{ github.event.inputs.deployment_type != 'redeploy-clean' && github.event.inputs.reset_database != 'true' }}
      run: |
        echo "üîÑ Performing smart cleanup (preserving data)..."
        
        # Create namespace if it doesn't exist
        kubectl create namespace zabbix --dry-run=client -o yaml | kubectl apply -f -
        
        # Only delete deployments and services, keep PVCs and secrets
        kubectl delete deployment --all -n zabbix --ignore-not-found=true
        kubectl delete service --all -n zabbix --ignore-not-found=true
        kubectl delete ingress --all -n zabbix --ignore-not-found=true
        
        # Wait for pods to terminate (but not MySQL pods)
        kubectl wait --for=delete pods -l app!=zabbix-mysql -n zabbix --timeout=60s || echo "‚ö†Ô∏è Some pods may still be terminating"
        
        echo "‚úÖ Smart cleanup completed - data preserved"

    - name: Deploy MySQL Database
      run: |
        kubectl apply -f k8s/zabbix-mysql.yaml
        
        # Wait for MySQL to be ready
        kubectl wait --for=condition=ready pod -l app=zabbix-mysql -n zabbix --timeout=600s

    - name: Initialize Zabbix Database with Complete Setup
      run: |
        echo "üóÑÔ∏è Initializing Zabbix database with complete schema and users..."
        
        # Wait for MySQL pod to be running
        kubectl wait --for=condition=ready pod -l app=zabbix-mysql -n zabbix --timeout=300s
        
        # Get MySQL pod name
        MYSQL_POD=$(kubectl get pods -n zabbix -l app=zabbix-mysql -o jsonpath='{.items[0].metadata.name}')
        echo "Using MySQL pod: $MYSQL_POD"
        
        # Check if database already exists (skip if it does)
        if kubectl exec -n zabbix $MYSQL_POD -- mysql -u zabbix -pzabbix_password -e "USE zabbix; SELECT 1;" 2>/dev/null; then
          echo "üìã Zabbix database already exists and accessible - skipping initialization"
        else
          echo "üìã Initializing new Zabbix database..."
          
          # Create database and user
          kubectl exec -n zabbix $MYSQL_POD -- mysql -u root -prootpassword -e "
            CREATE DATABASE IF NOT EXISTS zabbix CHARACTER SET utf8mb4 COLLATE utf8mb4_bin;
            CREATE USER IF NOT EXISTS 'zabbix'@'%' IDENTIFIED BY 'zabbix_password';
            GRANT ALL PRIVILEGES ON zabbix.* TO 'zabbix'@'%';
            FLUSH PRIVILEGES;"
          
          echo "‚úÖ Database and user created successfully"
        fi

    - name: Deploy Zabbix Server
      run: |
        echo "üöÄ Deploying Zabbix Server..."
        kubectl apply -f k8s/zabbix-server.yaml
        
        # Wait for Zabbix server to be ready
        kubectl wait --for=condition=ready pod -l app=zabbix-server -n zabbix --timeout=600s
        
        # Verify Zabbix server is running
        kubectl get pods -n zabbix -l app=zabbix-server
        echo "‚úÖ Zabbix Server deployed successfully"

    - name: Deploy Zabbix Web Frontend
      run: |
        echo "üåê Deploying Zabbix Web Frontend..."
        kubectl apply -f k8s/zabbix-web.yaml
        
        # Wait for web frontend to be ready
        kubectl wait --for=condition=ready pod -l app=zabbix-web -n zabbix --timeout=300s
        
        # Verify web frontend is running
        kubectl get pods -n zabbix -l app=zabbix-web
        echo "‚úÖ Zabbix Web Frontend deployed successfully"

    - name: Deploy Zabbix Agent
      run: |
        echo "üìä Deploying Zabbix Agent..."
        kubectl apply -f k8s/zabbix-agent.yaml
        
        # Wait for agent to be ready
        kubectl wait --for=condition=ready pod -l app=zabbix-agent -n zabbix --timeout=180s
        
        # Verify agent is running
        kubectl get pods -n zabbix -l app=zabbix-agent
        echo "‚úÖ Zabbix Agent deployed successfully"

    - name: Create Services and Ingress
      run: |
        echo "üîó Creating Zabbix services and ingress..."
        
        # Apply services
        kubectl apply -f k8s/zabbix-services.yaml
        
        # Apply ingress
        kubectl apply -f k8s/zabbix-ingress.yaml
        
        # Wait for services to be ready
        kubectl wait --for=condition=ready service/zabbix-web -n zabbix --timeout=60s
        
        # Show service information
        kubectl get services -n zabbix
        kubectl get ingress -n zabbix
        echo "‚úÖ Services and Ingress created successfully"

    - name: Verify Zabbix Deployment
      run: |
        echo "üîç Verifying complete Zabbix deployment..."
        
        # Check all pods are running
        kubectl get pods -n zabbix -o wide
        
        # Check services
        kubectl get services -n zabbix
        
        # Check ingress
        kubectl get ingress -n zabbix
        
        # Get Application Gateway IP for access
        APPGW_IP=$(az network public-ip show --resource-group ${{ env.AZURE_RESOURCE_GROUP }} --name pip-appgw-devops-eastus --query ipAddress -o tsv)
        echo "üåê Zabbix will be accessible at: http://$APPGW_IP/zabbix"
        echo "üìù Default credentials: Admin / zabbix"
        
        # Final verification - check if all expected pods are running
        EXPECTED_PODS=3  # MySQL, Server, Web
        RUNNING_PODS=$(kubectl get pods -n zabbix --field-selector=status.phase=Running --no-headers | wc -l)
        
        if [ "$RUNNING_PODS" -ge "$EXPECTED_PODS" ]; then
          echo "‚úÖ All Zabbix components are running successfully!"
          echo "DEPLOYMENT_SUCCESS=true" >> $GITHUB_OUTPUT
        else
          echo "‚ö†Ô∏è Some Zabbix components may not be fully ready yet"
          echo "   Running pods: $RUNNING_PODS / Expected: $EXPECTED_PODS"
          kubectl describe pods -n zabbix
          echo "DEPLOYMENT_SUCCESS=false" >> $GITHUB_OUTPUT
        fi

  # Deploy Application Only (Skip Infrastructure)
  deploy-zabbix-only:
    runs-on: ubuntu-latest
    environment: production
    if: ${{ github.event.inputs.deployment_type == 'application-only' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Azure CLI Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}

    - name: Install and Setup kubectl and Helm
      run: |
        echo "üîß Setting up kubectl and Helm..."
        
        # Install kubectl if not available
        if ! command -v kubectl &> /dev/null; then
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
        fi
        
        # Install Helm if not available
        if ! command -v helm &> /dev/null; then
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
        fi
        
        echo "‚úÖ kubectl and Helm are ready"

    - name: Get AKS credentials
      run: |
        echo "üîë Getting AKS credentials for application-only deployment..."
        echo "Cluster: ${{ env.AKS_CLUSTER_NAME }}"
        echo "Resource Group: ${{ env.AZURE_RESOURCE_GROUP }}"
        
        az aks get-credentials \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --name ${{ env.AKS_CLUSTER_NAME }} \
          --overwrite-existing
        
        # Verify connection
        kubectl cluster-info
        kubectl get nodes
        echo "‚úÖ AKS connection verified"

    - name: Deploy Zabbix Application (Application-Only Mode)
      run: |
        echo "üöÄ Deploying Zabbix application components..."
        
        # Create namespace
        kubectl create namespace zabbix --dry-run=client -o yaml | kubectl apply -f -
        
        # Apply all Zabbix resources
        kubectl apply -f k8s/zabbix-config.yaml
        kubectl apply -f k8s/zabbix-mysql.yaml
        kubectl apply -f k8s/zabbix-server.yaml  
        kubectl apply -f k8s/zabbix-web.yaml
        kubectl apply -f k8s/zabbix-agent.yaml
        kubectl apply -f k8s/zabbix-services.yaml
        kubectl apply -f k8s/zabbix-ingress.yaml
        
        # Wait for all pods to be ready
        echo "‚è≥ Waiting for all Zabbix components to be ready..."
        kubectl wait --for=condition=ready pod -l app=zabbix-mysql -n zabbix --timeout=600s
        kubectl wait --for=condition=ready pod -l app=zabbix-server -n zabbix --timeout=600s  
        kubectl wait --for=condition=ready pod -l app=zabbix-web -n zabbix --timeout=300s
        
        # Verify deployment
        kubectl get pods -n zabbix -o wide
        kubectl get services -n zabbix
        kubectl get ingress -n zabbix
        
        echo "‚úÖ Zabbix application deployed successfully in application-only mode!"

  # Final Status Report
  report-status:
    needs: [deploy-infrastructure, deploy-zabbix, deploy-zabbix-only]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Generate Deployment Report
      run: |
        echo "# üéØ **Zabbix AKS Deployment Report**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Run Details:**" >> $GITHUB_STEP_SUMMARY
        echo "- üèÉ **Run Number**: ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "- üë§ **Triggered By**: ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
        echo "- ‚ö° **Event**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- üéØ **Deployment Type**: ${{ env.DEPLOYMENT_TYPE }}" >> $GITHUB_STEP_SUMMARY
        echo "- üõ†Ô∏è  **Infrastructure Method**: ${{ env.INFRASTRUCTURE_METHOD }}" >> $GITHUB_STEP_SUMMARY
        echo "- üìä **Terraform Mode**: ${{ env.TERRAFORM_MODE }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "**Job Results:**" >> $GITHUB_STEP_SUMMARY
        echo "- üèóÔ∏è  **Infrastructure**: ${{ needs.deploy-infrastructure.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- üì± **Application (Full)**: ${{ needs.deploy-zabbix.result }}" >> $GITHUB_STEP_SUMMARY  
        echo "- üì± **Application (Only)**: ${{ needs.deploy-zabbix-only.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Determine overall success
        if [[ "${{ needs.deploy-zabbix.result }}" == "success" || "${{ needs.deploy-zabbix-only.result }}" == "success" ]]; then
          echo "**‚úÖ Overall Status: SUCCESS**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Next Steps:**" >> $GITHUB_STEP_SUMMARY
          echo "1. Configure DNS for dal2-devmon-mgt.forescout.com" >> $GITHUB_STEP_SUMMARY
          echo "2. Upload SSL certificate" >> $GITHUB_STEP_SUMMARY
          echo "3. Change default Zabbix admin password (Admin/zabbix)" >> $GITHUB_STEP_SUMMARY
          echo "4. Configure monitoring templates" >> $GITHUB_STEP_SUMMARY
        elif [[ "${{ needs.deploy-infrastructure.result }}" == "success" && "${{ env.DEPLOYMENT_TYPE }}" == "infrastructure-only" ]]; then
          echo "**‚úÖ Infrastructure Deployment: SUCCESS**" >> $GITHUB_STEP_SUMMARY
          echo "Infrastructure is ready for application deployment." >> $GITHUB_STEP_SUMMARY
        else
          echo "**‚ùå Overall Status: FAILED**" >> $GITHUB_STEP_SUMMARY
          echo "Check individual job logs for details." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Redeployment Options:**" >> $GITHUB_STEP_SUMMARY
        echo "- **Full Redeploy**: Use 'redeploy-clean' deployment type" >> $GITHUB_STEP_SUMMARY
        echo "- **App Only**: Use 'application-only' to redeploy just Zabbix" >> $GITHUB_STEP_SUMMARY
        echo "- **Infrastructure Only**: Use 'infrastructure-only' for infra changes" >> $GITHUB_STEP_SUMMARY
        echo "- **Reset Database**: Enable 'reset_database' option (‚ö†Ô∏è destroys data)" >> $GITHUB_STEP_SUMMARY
